{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNzvKgRZ7lDyJqZtgYwmXae",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samuelbernsen08/CS615/blob/main/CS615_FinalProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text embedding way"
      ],
      "metadata": {
        "id": "AqJkkLqr2KVd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qWB64LoyM0uu"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained VGG16 model\n",
        "vgg_conv = kb.applications.vgg16.VGG16(\n",
        "    weights = \"imagenet\",\n",
        "    # include_top = False, # only including the convolution and pooling layers, not the dense FF layers\n",
        "    input_shape = (224,224,3)\n",
        ")"
      ],
      "metadata": {
        "id": "qPpt2dc9QY4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the image for inference\n",
        "img_paths = ['/content/997_911_gt2rs.jpg', '/content/snick.jpg','/content/DSC_6846.JPG','/content/DSC_9220.JPG','/content/playfulsherbie1.jpg','/content/Sprite_LeBron_Commercial.jpg']\n",
        "images = []\n",
        "x = []\n",
        "predictions = [None] * len(img_paths)  # Initialize the predictions list with the same length as the x list\n",
        "decoded_predictions = [None] * len(img_paths)  # Initialize the predictions list with the same length as the x list\n",
        "storage = []\n",
        "for i in range(len(img_paths)):\n",
        "    images.append(image.load_img(img_paths[i], target_size=(224, 224)))  # VGG16 input size is (224, 224)\n",
        "\n",
        "    # Preprocess the image\n",
        "    x.append(image.img_to_array(images[i]))\n",
        "    x[i] = np.expand_dims(x[i], axis=0)\n",
        "    x[i] = preprocess_input(x[i])\n",
        "\n",
        "    # Run inference\n",
        "    predictions[i] = vgg_conv.predict(x[i])\n",
        "\n",
        "    # Decode the predictions\n",
        "    decoded_predictions[i] = decode_predictions(predictions[i], top=1)[0]  # Get the top predicted classes\n",
        "\n",
        "# Grab the second entries in each list\n",
        "labels = [sublist[0][1] for sublist in decoded_predictions]\n",
        "\n",
        "for i in range(len(labels)):\n",
        "    storage.append([img_paths[i], labels[i]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nx2tswgkZCtD",
        "outputId": "8206dee9-5869-437f-bb3c-5600ebc9016f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 731ms/step\n",
            "1/1 [==============================] - 1s 590ms/step\n",
            "1/1 [==============================] - 1s 579ms/step\n",
            "1/1 [==============================] - 1s 577ms/step\n",
            "1/1 [==============================] - 1s 568ms/step\n",
            "1/1 [==============================] - 1s 585ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYtvrJmNsRBw",
        "outputId": "a9c6936e-cb50-432b-9414-5339ca41e841"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('n03100240', 'convertible', 0.6443795)],\n",
              " [('n02951585', 'can_opener', 0.06589259)],\n",
              " [('n03877472', 'pajama', 0.11703915)],\n",
              " [('n09332890', 'lakeside', 0.48314404)],\n",
              " [('n02123159', 'tiger_cat', 0.22071552)],\n",
              " [('n02927161', 'butcher_shop', 0.2739127)]]"
            ]
          },
          "metadata": {},
          "execution_count": 670
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load GloVe word vectors\n",
        "def load_glove_vectors(glove_file):\n",
        "    word_vectors = {}\n",
        "    with open(glove_file, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            vector = np.asarray(values[1:], dtype='float32')\n",
        "            word_vectors[word] = vector\n",
        "    return word_vectors\n",
        "\n",
        "def cosine_similarity(a, b):\n",
        "    dot_product = np.dot(a, b)\n",
        "    norm_a = np.linalg.norm(a)\n",
        "    norm_b = np.linalg.norm(b)\n",
        "    similarity = dot_product / (norm_a * norm_b)\n",
        "    return similarity\n",
        "\n",
        "# Function to embed a string using GloVe\n",
        "def embed_string(string, word_vectors):\n",
        "    words = string.split()\n",
        "    embedding = np.zeros(word_vectors['the'].shape)  # Initialize embedding with zeros\n",
        "    for word in words:\n",
        "        if word in word_vectors:\n",
        "            embedding += word_vectors[word]\n",
        "    return embedding / len(words)  # Normalize by the number of words\n",
        "\n",
        "\n",
        "glove_file = '/content/glove.6B.50d.txt'  # Path to the GloVe file\n",
        "word_vectors = load_glove_vectors(glove_file)"
      ],
      "metadata": {
        "id": "od2Si4olQxAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_underscores(string):\n",
        "    return string.replace(\"_\", \" \")"
      ],
      "metadata": {
        "id": "VR-ohlwHfy5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "strings = []\n",
        "for i in range(len(labels)):\n",
        "  strings.append(remove_underscores(storage[i][1]))"
      ],
      "metadata": {
        "id": "ab5CltvWWlRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_vectors = []\n",
        "for i in range(len(strings)):\n",
        "  embedding_vectors.append(embed_string(strings[i], word_vectors))\n",
        "\n",
        "# similarities = []\n",
        "# for i in range(len(embedding_vectors)-1):\n",
        "#   for j in range(len(embedding_vectors)-1):\n",
        "#     if i != (j+1):\n",
        "#       similarities.append(cosine_similarity(embedding_vectors[i], embedding_vectors[j+1]))\n",
        "\n",
        "similarities = []\n",
        "for i in range(len(embedding_vectors)-1):\n",
        "  similarities.append(cosine_similarity(embedding_vectors[0], embedding_vectors[i+1]))\n",
        "\n",
        "print(similarities)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5U0AlxS8Qua7",
        "outputId": "67e02c36-f94d-432a-911b-f087e5141694"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.06552728130699631, 0.1586576165758021, 0.12359108221283541, 0.15830228340621189, 0.09819478733086058]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "highest_similarity = max(similarities)\n",
        "highest_similarity_index = similarities.index(highest_similarity)"
      ],
      "metadata": {
        "id": "JWsuHjIWksMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "highest_similarity_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTq3flFxGAX6",
        "outputId": "47b58440-88f3-4ddd-a121-f8dfee46dcac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 676
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next_image = storage[highest_similarity_index+1][0]\n",
        "next_image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "6gpTw4n6k8RH",
        "outputId": "619ee0aa-29af-4fdc-d35e-debaae7fa346"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/DSC_6846.JPG'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 677
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "TMXzfQiSEA_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "highest_similarity_index = -1\n",
        "p = 0\n",
        "for k in range(len(storage)):\n",
        "    similarities = []\n",
        "    for i in range(len(storage)):\n",
        "      if (i+k+1) <= len(storage) - 1:\n",
        "        similarities.append(cosine_similarity(embedding_vectors[k], embedding_vectors[i+k+1]))\n",
        "    highest_similarity = max(similarities)\n",
        "    highest_similarity_index = similarities.index(highest_similarity) + 1\n",
        "\n",
        "    if k < len(storage)-1:\n",
        "      temp_k1 = embedding_vectors[1]\n",
        "      temp_stor_k1 = storage[1]\n",
        "      temp_high = embedding_vectors[highest_similarity_index+1]\n",
        "      temp_stor_high = storage[highest_similarity_index+1]\n",
        "\n",
        "      embedding_vectors[1] = embedding_vectors[highest_similarity_index+1]\n",
        "      embedding_vectors[highest_similarity_index] = temp_k1\n",
        "      temp_high = temp_k1\n",
        "      temp_stor_high = temp_stor_k1\n",
        "\n",
        "      storage[1] = storage[highest_similarity_index+1]\n",
        "      storage[highest_similarity_index+1] = temp_stor_k1\n",
        "      temp_stor_high = temp_stor_k1\n",
        "\n",
        "      p += 1\n",
        "print(p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "yg---bs6rb_d",
        "outputId": "f3a54234-3506-4919-e0da-cf2c15864b23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "max() arg is an empty sequence",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-606-910922e52c6e>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0msimilarities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_vectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_vectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mhighest_similarity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimilarities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mhighest_similarity_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimilarities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhighest_similarity\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: max() arg is an empty sequence"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for k in range(len(storage)):\n",
        "    similarities = []\n",
        "    for i in range(len(storage)):\n",
        "        if i != k:\n",
        "            similarity = cosine_similarity(embedding_vectors[k], embedding_vectors[i])\n",
        "            similarities.append(similarity)\n",
        "    highest_similarity_index = similarities.index(max(similarities)) + 1\n",
        "\n",
        "    # Swap embedding vectors and corresponding storage entries\n",
        "    temp_k = embedding_vectors[k].copy()\n",
        "    embedding_vectors[k] = embedding_vectors[highest_similarity_index].copy()\n",
        "    embedding_vectors[highest_similarity_index] = temp_k\n",
        "\n",
        "    temp_stor = storage[k]\n",
        "    storage[k] = storage[highest_similarity_index]\n",
        "    storage[highest_similarity_index] = temp_stor\n",
        "\n",
        "print(p)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKZ3v6QGL4bS",
        "outputId": "9c37b9cb-cb83-4915-b7bc-4b53c6bcb75a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "storage"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhwPn5CfNacz",
        "outputId": "5ab957fa-71d6-4de6-bf8d-86b7f041bea4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['/content/DSC_6846.JPG', 'pajama'],\n",
              " ['/content/997_911_gt2rs.jpg', 'convertible'],\n",
              " ['/content/playfulsherbie1.jpg', 'tiger_cat'],\n",
              " ['/content/snick.jpg', 'can_opener'],\n",
              " ['/content/Sprite_LeBron_Commercial.jpg', 'butcher_shop'],\n",
              " ['/content/DSC_9220.JPG', 'lakeside']]"
            ]
          },
          "metadata": {},
          "execution_count": 679
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for k in range(len(storage)):\n",
        "    similarities = []\n",
        "    for i in range(len(storage)-1):\n",
        "      if (i+k+1) <= len(storage) - 1:\n",
        "        similarities.append(cosine_similarity(embedding_vectors[k], embedding_vectors[i+k+1]))\n",
        "    highest_similarity = max(similarities)\n",
        "    highest_similarity_index = similarities.index(highest_similarity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "lUlkIc7XLjgS",
        "outputId": "a1b2eb02-e4ad-4015-ec04-a5e05e74c834"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "max() arg is an empty sequence",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-608-0c47f8eb3cb2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0msimilarities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_vectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_vectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mhighest_similarity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimilarities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mhighest_similarity_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimilarities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhighest_similarity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: max() arg is an empty sequence"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "highest_similarity_index = -1\n",
        "\n",
        "for k in range(len(storage)):\n",
        "    similarities = []\n",
        "    i = len(storage) - 1\n",
        "    while i > 1:\n",
        "      similarities.append(cosine_similarity(embedding_vectors[k], embedding_vectors[i]))\n",
        "    highest_similarity = max(similarities)\n",
        "    highest_similarity_index = similarities.index(highest_similarity)\n",
        "\n",
        "    if k < len(storage)-1:\n",
        "      temp_k1 = embedding_vectors[1]\n",
        "      temp_stor_k1 = storage[1]\n",
        "      temp_high = embedding_vectors[highest_similarity_index+1]\n",
        "      temp_stor_high = storage[highest_similarity_index+1]\n",
        "\n",
        "      embedding_vectors[1] = embedding_vectors[highest_similarity_index+1]\n",
        "      embedding_vectors[highest_similarity_index] = temp_k1\n",
        "      temp_high = temp_k1\n",
        "      temp_stor_high = temp_stor_k1\n",
        "\n",
        "      storage[1] = storage[highest_similarity_index+1]\n",
        "      storage[highest_similarity_index+1] = temp_stor_k1\n",
        "      temp_stor_high = temp_stor_k1\n",
        "\n",
        "storage"
      ],
      "metadata": {
        "id": "qPYn2RXvJ4WJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similarities = []\n",
        "for i in range(len(storage)-1):\n",
        "  highest_similarity_index = 0\n",
        "  similarities.append(cosine_similarity(embedding_vectors[highest_similarity_index], embedding_vectors[i+1]))\n",
        "\n",
        "highest_similarity = max(similarities)\n",
        "highest_similarity_index = similarities.index(highest_similarity)\n",
        "\n",
        "temp_k1 = embedding_vectors[1]\n",
        "temp_stor_k1 = storage[1]\n",
        "temp_high = embedding_vectors[highest_similarity_index+1]\n",
        "temp_stor_high = storage[highest_similarity_index+1]\n",
        "\n",
        "embedding_vectors[1] = embedding_vectors[highest_similarity_index+1]\n",
        "storage[1] = storage[highest_similarity_index+1]\n",
        "storage[highest_similarity_index+1] = temp_stor_k1\n",
        "temp_stor_high = temp_stor_k1\n",
        "\n",
        "highest_similarity_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uypcvWi67wAP",
        "outputId": "c37274a8-ae5c-416b-bc7c-6b917c7d6eda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 610
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "storage"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3D1fGSbDupG",
        "outputId": "82f6a226-4d6c-4eb8-d237-fcde43850482"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['/content/playfulsherbie1.jpg', 'tiger_cat'],\n",
              " ['/content/snick.jpg', 'can_opener'],\n",
              " ['/content/997_911_gt2rs.jpg', 'convertible'],\n",
              " ['/content/DSC_9220.JPG', 'lakeside'],\n",
              " ['/content/DSC_6846.JPG', 'pajama']]"
            ]
          },
          "metadata": {},
          "execution_count": 664
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_vectors = []\n",
        "for i in range(len(strings)):\n",
        "  embedding_vectors.append(embed_string(strings[i], word_vectors))\n",
        "\n",
        "# similarities = []\n",
        "# for i in range(len(embedding_vectors)-1):\n",
        "#   for j in range(len(embedding_vectors)-1):\n",
        "#     if i != (j+1):\n",
        "#       similarities.append(cosine_similarity(embedding_vectors[i], embedding_vectors[j+1]))\n",
        "\n",
        "similarities = []\n",
        "for i in range(len(embedding_vectors)-1):\n",
        "  similarities.append(cosine_similarity(remove_underscores(storage[0][1]), remove_underscores(storage[i+1][1])))\n",
        "\n",
        "print(similarities)"
      ],
      "metadata": {
        "id": "GJ8B81mDNrXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat = embed_string(\"tiger cat\", word_vectors)\n",
        "lakeside = embed_string(\"lakeside\", word_vectors)\n",
        "convertible = embed_string(\"convertible\", word_vectors)\n",
        "can_opener = embed_string(\"can opener\", word_vectors)\n",
        "pajama = embed_string(\"pajama\", word_vectors)\n",
        "butcher = embed_string(\"butcher shop\", word_vectors)\n",
        "\n",
        "print(cosine_similarity(cat,lakeside))\n",
        "print(cosine_similarity(cat,convertible))\n",
        "print(cosine_similarity(cat,can_opener))\n",
        "print(cosine_similarity(cat,pajama))\n",
        "print(cosine_similarity(cat,butcher))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5w8FPkxOPVW",
        "outputId": "8f3a5c68-e385-417f-bbb1-4b252cdf72db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.08192158007767039\n",
            "0.15830228340621189\n",
            "0.5186216978940044\n",
            "0.34653582721914733\n",
            "0.39043469117244045\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(cosine_similarity(lakeside,cat))\n",
        "print(cosine_similarity(lakeside,convertible))\n",
        "print(cosine_similarity(lakeside,can_opener))\n",
        "print(cosine_similarity(lakeside,pajama))\n",
        "print(cosine_similarity(lakeside,butcher))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiehICy1PpCu",
        "outputId": "dd0831eb-1816-45ef-9941-1561e72e1259"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.08192158007767039\n",
            "0.12359108221283541\n",
            "-0.004699733250499103\n",
            "0.08061996728599555\n",
            "0.24157731609041283\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(cosine_similarity(pajama,lakeside))\n",
        "print(cosine_similarity(pajama,cat))\n",
        "print(cosine_similarity(pajama,can_opener))\n",
        "print(cosine_similarity(pajama,convertible))\n",
        "print(cosine_similarity(pajama,butcher))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tG4ZHcyCPvTR",
        "outputId": "af662bcb-6e5a-48a0-e494-6bd13ab20f66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.08061996728599555\n",
            "0.34653582721914733\n",
            "0.007765167446413493\n",
            "0.1586576165758021\n",
            "0.161078399447504\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(cosine_similarity(can_opener,convertible))\n",
        "print(cosine_similarity(can_opener,cat))\n",
        "print(cosine_similarity(can_opener,pajama))\n",
        "print(cosine_similarity(can_opener,lakeside))\n",
        "print(cosine_similarity(can_opener,butcher))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQVlFROhQnFK",
        "outputId": "e64ad1b3-8441-4b7d-e887-3b7be22887c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.06552728130699631\n",
            "0.5186216978940044\n",
            "0.007765167446413493\n",
            "-0.004699733250499103\n",
            "0.4202344306177217\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(cosine_similarity(convertible,can_opener))\n",
        "print(cosine_similarity(convertible,cat))\n",
        "print(cosine_similarity(convertible,pajama))\n",
        "print(cosine_similarity(convertible,lakeside))\n",
        "print(cosine_similarity(convertible,butcher))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuDSxqxhRG_e",
        "outputId": "9d783147-875d-4c82-a324-c98d36fb74de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.06552728130699631\n",
            "0.15830228340621189\n",
            "0.1586576165758021\n",
            "0.12359108221283541\n",
            "0.09819478733086058\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "similarities"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4gNF1DR9d8a",
        "outputId": "2453efff-fbdd-470b-9895-cc8007f452d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.08192158007767039,\n",
              " 0.08192158007767039,\n",
              " 0.08192158007767039,\n",
              " 0.15830228340621189]"
            ]
          },
          "metadata": {},
          "execution_count": 613
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "HEJB2gwwEtz8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Image feature way"
      ],
      "metadata": {
        "id": "mofYYZbK2ILf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Load VGG16 model\n",
        "vgg_model = VGG16(weights='imagenet', include_top=False)\n",
        "\n",
        "# Function to preprocess image and extract features using VGG16\n",
        "def extract_features(image_path):\n",
        "    img = image.load_img(image_path, target_size=(224, 224))\n",
        "    img = image.img_to_array(img)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    img = preprocess_input(img)\n",
        "    features = vgg_model.predict(img)\n",
        "    features = features.flatten()  # Flatten to get a 1D feature vector\n",
        "    return features\n",
        "\n",
        "# List of image paths\n",
        "image_paths = ['/content/997_911_gt2rs.jpg', '/content/snick.jpg', '/content/DSC_6846.JPG', '/content/DSC_9220.JPG', '/content/playfulsherbie1.jpg']\n",
        "\n",
        "# Extract features for each image\n",
        "features_list = [extract_features(img_path) for img_path in image_paths]\n",
        "\n",
        "# Calculate cosine similarity between every pair of images\n",
        "cosine_similarities = cosine_similarity(features_list, features_list)\n",
        "\n",
        "# Print cosine similarity matrix\n",
        "print(cosine_similarities)\n"
      ],
      "metadata": {
        "id": "OqGSsTUP1p03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "# Load the pre-trained VGG16 model\n",
        "vgg_conv = tf.keras.applications.vgg16.VGG16(\n",
        "    weights=\"imagenet\",\n",
        "    # include_top=False, # only including the convolution and pooling layers, not the dense FF layers\n",
        "    input_shape=(224, 224, 3)\n",
        ")\n",
        "\n",
        "# Load GloVe word vectors\n",
        "def load_glove_vectors(glove_file):\n",
        "    word_vectors = {}\n",
        "    with open(glove_file, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            vector = np.asarray(values[1:], dtype='float32')\n",
        "            word_vectors[word] = vector\n",
        "    return word_vectors\n",
        "\n",
        "# Function to embed a string using GloVe\n",
        "def embed_string(string, word_vectors):\n",
        "    words = string.split()\n",
        "    embedding = np.zeros(word_vectors['the'].shape)  # Initialize embedding with zeros\n",
        "    for word in words:\n",
        "        if word in word_vectors:\n",
        "            embedding += word_vectors[word]\n",
        "    return embedding / len(words)  # Normalize by the number of words\n",
        "\n",
        "def cosine_similarity(a, b):\n",
        "    dot_product = np.dot(a, b)\n",
        "    norm_a = np.linalg.norm(a)\n",
        "    norm_b = np.linalg.norm(b)\n",
        "    similarity = dot_product / (norm_a * norm_b)\n",
        "    return similarity\n",
        "\n",
        "glove_file = '/content/glove.6B.50d.txt'  # Path to the GloVe file\n",
        "word_vectors = load_glove_vectors(glove_file)\n",
        "\n",
        "# Load the image for inference\n",
        "img_paths = ['/content/997_911_gt2rs.jpg', '/content/snick.jpg','/content/DSC_6846.JPG','/content/DSC_9220.JPG','/content/playfulsherbie1.jpg']\n",
        "images = []\n",
        "x = []\n",
        "predictions = [None] * len(img_paths)  # Initialize the predictions list with the same length as the x list\n",
        "decoded_predictions = [None] * len(img_paths)  # Initialize the predictions list with the same length as the x list\n",
        "storage = []\n",
        "for i in range(len(img_paths)):\n",
        "    images.append(image.load_img(img_paths[i], target_size=(224, 224)))  # VGG16 input size is (224, 224)\n",
        "\n",
        "    # Preprocess the image\n",
        "    x.append(image.img_to_array(images[i]))\n",
        "    x[i] = np.expand_dims(x[i], axis=0)\n",
        "    x[i] = preprocess_input(x[i])\n",
        "\n",
        "    # Run inference\n",
        "    predictions[i] = vgg_conv.predict(x[i])\n",
        "\n",
        "    # Decode the predictions\n",
        "    decoded_predictions[i] = decode_predictions(predictions[i], top=1)[0]  # Get the top predicted classes\n",
        "\n",
        "# Grab the second entries in each list\n",
        "labels = [sublist[0][1] for sublist in decoded_predictions]\n",
        "\n",
        "for i in range(len(labels)):\n",
        "    storage.append([img_paths[i], labels[i]])\n",
        "\n",
        "# Prepare image labels\n",
        "labels = [remove_underscores(sublist[1]) for sublist in storage]\n",
        "\n",
        "# Embed image labels using GloVe\n",
        "embedding_vectors = [embed_string(label, word_vectors) for label in labels]\n",
        "\n",
        "# Calculate cosine similarity between embeddings\n",
        "similarities = []\n",
        "for i in range(len(embedding_vectors)-1):\n",
        "    similarities.append(cosine_similarity(embedding_vectors[0], embedding_vectors[i+1]))\n",
        "\n",
        "# Rearrange images based on similarities\n",
        "sorted_indices = sorted(range(len(similarities)), key=lambda i: similarities[i], reverse=True)\n",
        "sorted_indices = [i+1 for i in sorted_indices]  # Adjust indices since we skipped the first image\n",
        "sorted_images = [storage[i] for i in sorted_indices]\n",
        "\n",
        "sorted_images  # This will give you the images organized by their similarities\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8psiftXdTMpE",
        "outputId": "c26f5d2e-cfec-48dd-a407-314bc2442c66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 1s 631ms/step\n",
            "1/1 [==============================] - 1s 575ms/step\n",
            "1/1 [==============================] - 1s 561ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['/content/DSC_6846.JPG', 'pajama'],\n",
              " ['/content/playfulsherbie1.jpg', 'tiger_cat'],\n",
              " ['/content/DSC_9220.JPG', 'lakeside'],\n",
              " ['/content/snick.jpg', 'can_opener']]"
            ]
          },
          "metadata": {},
          "execution_count": 685
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "HcrbfQTKVp8m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##This is from help with Chat: It works by itself, as long as you import GLOVE and images with the paths copied correctly"
      ],
      "metadata": {
        "id": "nfxaHuhbVgw3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load the pre-trained VGG16 model\n",
        "vgg_conv = tf.keras.applications.vgg16.VGG16(\n",
        "    weights=\"imagenet\",\n",
        "    # include_top=False, # only including the convolution and pooling layers, not the dense FF layers\n",
        "    input_shape=(224, 224, 3)\n",
        ")\n",
        "\n",
        "# Load GloVe word vectors\n",
        "def load_glove_vectors(glove_file):\n",
        "    word_vectors = {}\n",
        "    with open(glove_file, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            vector = np.asarray(values[1:], dtype='float32')\n",
        "            word_vectors[word] = vector\n",
        "    return word_vectors\n",
        "\n",
        "# Function to embed a string using GloVe\n",
        "def embed_string(string, word_vectors):\n",
        "    words = string.split()\n",
        "    embedding = np.zeros(word_vectors['the'].shape)  # Initialize embedding with zeros\n",
        "    for word in words:\n",
        "        if word in word_vectors:\n",
        "            embedding += word_vectors[word]\n",
        "    return embedding / len(words)  # Normalize by the number of words\n",
        "\n",
        "glove_file = '/content/glove.6B.50d.txt'  # Path to the GloVe file\n",
        "word_vectors = load_glove_vectors(glove_file)\n",
        "\n",
        "# Load the image for inference\n",
        "img_paths = ['/content/997_911_gt2rs.jpg', '/content/snick.jpg','/content/DSC_6846.JPG','/content/DSC_9220.JPG','/content/playfulsherbie1.jpg']\n",
        "images = []\n",
        "x = []\n",
        "predictions = [None] * len(img_paths)  # Initialize the predictions list with the same length as the x list\n",
        "decoded_predictions = [None] * len(img_paths)  # Initialize the predictions list with the same length as the x list\n",
        "storage = []\n",
        "for i in range(len(img_paths)):\n",
        "    images.append(image.load_img(img_paths[i], target_size=(224, 224)))  # VGG16 input size is (224, 224)\n",
        "\n",
        "    # Preprocess the image\n",
        "    x.append(image.img_to_array(images[i]))\n",
        "    x[i] = np.expand_dims(x[i], axis=0)\n",
        "    x[i] = preprocess_input(x[i])\n",
        "\n",
        "    # Run inference\n",
        "    predictions[i] = vgg_conv.predict(x[i])\n",
        "\n",
        "    # Decode the predictions\n",
        "    decoded_predictions[i] = decode_predictions(predictions[i], top=1)[0]  # Get the top predicted classes\n",
        "\n",
        "# Grab the second entries in each list\n",
        "labels = [sublist[0][1] for sublist in decoded_predictions]\n",
        "\n",
        "for i in range(len(labels)):\n",
        "    storage.append([img_paths[i], labels[i]])\n",
        "\n",
        "# Prepare image labels\n",
        "labels = [remove_underscores(sublist[1]) for sublist in storage]\n",
        "\n",
        "# Embed image labels using GloVe\n",
        "embedding_vectors = [embed_string(label, word_vectors) for label in labels]\n",
        "\n",
        "# Calculate cosine similarity between embeddings\n",
        "similarities = cosine_similarity(embedding_vectors, embedding_vectors)\n",
        "\n",
        "# Rearrange images based on similarities\n",
        "sorted_indices = similarities.argsort(axis=None)[::-1]\n",
        "\n",
        "# Ensure sorted indices are within valid range\n",
        "valid_sorted_indices = [i for i in sorted_indices if i < len(storage)]\n",
        "\n",
        "# Obtain sorted images based on valid sorted indices\n",
        "sorted_images = [storage[i] for i in valid_sorted_indices]\n",
        "\n",
        "sorted_images  # This will give you the images organized by their similarities\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qozjx6AWT9eU",
        "outputId": "d942c8de-ab0f-45c6-eaa0-ed635415dc94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 708ms/step\n",
            "1/1 [==============================] - 1s 599ms/step\n",
            "1/1 [==============================] - 1s 564ms/step\n",
            "1/1 [==============================] - 1s 588ms/step\n",
            "1/1 [==============================] - 1s 583ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['/content/997_911_gt2rs.jpg', 'convertible'],\n",
              " ['/content/DSC_6846.JPG', 'pajama'],\n",
              " ['/content/playfulsherbie1.jpg', 'tiger_cat'],\n",
              " ['/content/DSC_9220.JPG', 'lakeside'],\n",
              " ['/content/snick.jpg', 'can_opener']]"
            ]
          },
          "metadata": {},
          "execution_count": 691
        }
      ]
    }
  ]
}